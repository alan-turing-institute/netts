{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to netts Network of Transcript Semantics (netts) creates networks capturing the semantic content of speech. Network of Transcript Semantics Documentation : https://alan-turing-institute.github.io/netts/ Source Code : https://github.com/alan-turing-institute/netts About Netts is package for analysing the content of natural speech. It maps the content of speech as a network and analyses the network using graph theory. The networks are referred to as semantic speech networks . This is novel analysis method for speech data has provided new insight on speech alterations in psychiatric conditions. Netts uses Natural Language Processing (NLP) to construct speech networks from transcripts of spoken text (e.g. I see a man ). Nodes represent entities (e.g. I , man ) and edges represent relations between nodes (e.g. see ). The tool is freely available as a python package and accessible online. It can be installed from the python package index PyPI, see Getting Started for installation instructions. Netts can be used to construct a semantic speech network from a text file with a single command. See CLI usage for a user guide. For a detailed explanation of the processing pipeline, see Pipeline . Contributors Netts was written by Caroline Nettekoven in collaboration with Sarah Morgan . Netts was packaged in collaboration with Oscar Giles , Iain Stenson and Helen Duncan . Links PyPI Github Brain Mapping Unit Computational Psychiatry Group Alan Turing Institute","title":"Overview"},{"location":"#welcome-to-netts","text":"Network of Transcript Semantics (netts) creates networks capturing the semantic content of speech. Network of Transcript Semantics Documentation : https://alan-turing-institute.github.io/netts/ Source Code : https://github.com/alan-turing-institute/netts","title":"Welcome to netts"},{"location":"#about","text":"Netts is package for analysing the content of natural speech. It maps the content of speech as a network and analyses the network using graph theory. The networks are referred to as semantic speech networks . This is novel analysis method for speech data has provided new insight on speech alterations in psychiatric conditions. Netts uses Natural Language Processing (NLP) to construct speech networks from transcripts of spoken text (e.g. I see a man ). Nodes represent entities (e.g. I , man ) and edges represent relations between nodes (e.g. see ). The tool is freely available as a python package and accessible online. It can be installed from the python package index PyPI, see Getting Started for installation instructions. Netts can be used to construct a semantic speech network from a text file with a single command. See CLI usage for a user guide. For a detailed explanation of the processing pipeline, see Pipeline .","title":"About"},{"location":"#contributors","text":"Netts was written by Caroline Nettekoven in collaboration with Sarah Morgan . Netts was packaged in collaboration with Oscar Giles , Iain Stenson and Helen Duncan .","title":"Contributors"},{"location":"#links","text":"PyPI Github Brain Mapping Unit Computational Psychiatry Group Alan Turing Institute","title":"Links"},{"location":"cli/","text":"CLI CLI Arguments When you install the netts package, you also get the netts commandline interface (CLI). To see all of the commands and options for the CLI, run: netts --help Each netts sub command also supports the --help option. The Run Command The netts run command will process a transcript (or directory of transcripts), building semantic MultiDiGraphs and saving them as pickled Python objects to the specified output directory. By default, netts will also draw the graphs and save them in .png format next to the pickled objects. netts run my_transcripts output_folder my_transcripts/ \u251c\u2500 transcript_1.txt \u251c\u2500 transcript_2.txt output_folder/ \u251c\u2500 transcript_1.pickle \u251c\u2500 transcript_1.png \u251c\u2500 transcript_2.pickle \u251c\u2500 transcript_2.png The netts run command has a few optional parameters: Pattern You can pass a glob pathname to filter files to process in a directory. For example, if we only wanted to process files in INPUT_DIR with the suffix _monday.txt , we could use: CLI netts run DIRECTORY OUTPUT_DIR --pattern \"*_monday.txt\" Force By default netts will not reprocess a file if it already exists in the output dir. If you wish to reprocess it again add the --force flag. CLI netts run INPUT_DIR_OR_FILE OUTPUT_DIR --force Figure By default netts run will create a figures and output them to OUTPUT_DIR . If you don't want figures, add the --no-figure flag: CLI netts run INPUT_DIR_OR_FILE OUTPUT_DIR --no-figure You can also change the figure format, which will except any format supported by Matplotlib : CLI netts run INPUT_DIR_OR_FILE OUTPUT_DIR --fig-format .jpeg","title":"Options"},{"location":"cli/#cli","text":"","title":"CLI"},{"location":"cli/#cli-arguments","text":"When you install the netts package, you also get the netts commandline interface (CLI). To see all of the commands and options for the CLI, run: netts --help Each netts sub command also supports the --help option.","title":"CLI Arguments"},{"location":"cli/#the-run-command","text":"The netts run command will process a transcript (or directory of transcripts), building semantic MultiDiGraphs and saving them as pickled Python objects to the specified output directory. By default, netts will also draw the graphs and save them in .png format next to the pickled objects. netts run my_transcripts output_folder my_transcripts/ \u251c\u2500 transcript_1.txt \u251c\u2500 transcript_2.txt output_folder/ \u251c\u2500 transcript_1.pickle \u251c\u2500 transcript_1.png \u251c\u2500 transcript_2.pickle \u251c\u2500 transcript_2.png The netts run command has a few optional parameters:","title":"The Run Command"},{"location":"cli/#pattern","text":"You can pass a glob pathname to filter files to process in a directory. For example, if we only wanted to process files in INPUT_DIR with the suffix _monday.txt , we could use: CLI netts run DIRECTORY OUTPUT_DIR --pattern \"*_monday.txt\"","title":"Pattern"},{"location":"cli/#force","text":"By default netts will not reprocess a file if it already exists in the output dir. If you wish to reprocess it again add the --force flag. CLI netts run INPUT_DIR_OR_FILE OUTPUT_DIR --force","title":"Force"},{"location":"cli/#figure","text":"By default netts run will create a figures and output them to OUTPUT_DIR . If you don't want figures, add the --no-figure flag: CLI netts run INPUT_DIR_OR_FILE OUTPUT_DIR --no-figure You can also change the figure format, which will except any format supported by Matplotlib : CLI netts run INPUT_DIR_OR_FILE OUTPUT_DIR --fig-format .jpeg","title":"Figure"},{"location":"cli_basics/","text":"Command Line Netts takes speech transcripts and converts them into a semantic graph. Imagine we have the following short transcript in a file called transcript.txt : I see a man and he is wearing a jacket. He is standing in the dark against a light post. On the picture there seems to be like a park and... Or trees but in those trees there are little balls of light reflections as well. I cannot see the... Anything else because it\u2019s very dark. But the man on the picture seems to wear a hat and he seems to have a hoodie on as well. The picture is very mysterious, which I like about it, but for me I would like to understand more about the picture. Follow along - Example transcript To follow along create this example in a file by running the following command in a terminal echo \"I see a man and he is wearing a jacket. He is standing in the dark against a light post. On the picture there seems to be like a park and... Or trees but in those trees there are little balls of light reflections as well. I cannot see the... Anything else because it\u2019s very dark. But the man on the picture seems to wear a hat and he seems to have a hoodie on as well. The picture is very mysterious, which I like about it, but for me I would like to understand more about the picture.\" > transcript.txt Create a semantic graph We can create a semantic graph from the transcript using either the command line interface (CLI) of python package. We can process a single transcript with the CLI like this CLI netts run transcript.txt outputs We can break this down into the following components: CLI Command transcript.txt outputs netts run Path to transcript path of output directory transcript.txt can be replaced with the full path to any .txt file. outputs can be replaced with the path to any directory. If the directory does not exist yet netts will create it. Netts uses Openie5 and CoreNLP under the hood. These are both Java programmes that we installed in the previous step. We use a context manager to start the servers, which makes sure they are both automatically shut down when processing finishes. Warning The servers are extremely memory hungry, using ~8GB. If the server fails to start you probably ran out of memory and failed silently. Try on a machine with more memory. Outputs Once netts processes the transcript the output directory will contain two files: outputs/ transcript.pickle transcript.png The file prefix is taken from the input file (in this case transcript .txt ) transcript .pickle : A NetworkX MiltiDiGraph object. transcript .png : A plot of the graph. Process a directory of transcripts If you have a folder of transcripts you can process the entire folder with the CLI. For example, if you have a folder called all_transcripts : all_transcripts/ transcript_1.txt transcript_2.txt ... you can process it with CLI netts run all_transcripts outputs","title":"Basic"},{"location":"cli_basics/#command-line","text":"Netts takes speech transcripts and converts them into a semantic graph. Imagine we have the following short transcript in a file called transcript.txt : I see a man and he is wearing a jacket. He is standing in the dark against a light post. On the picture there seems to be like a park and... Or trees but in those trees there are little balls of light reflections as well. I cannot see the... Anything else because it\u2019s very dark. But the man on the picture seems to wear a hat and he seems to have a hoodie on as well. The picture is very mysterious, which I like about it, but for me I would like to understand more about the picture. Follow along - Example transcript To follow along create this example in a file by running the following command in a terminal echo \"I see a man and he is wearing a jacket. He is standing in the dark against a light post. On the picture there seems to be like a park and... Or trees but in those trees there are little balls of light reflections as well. I cannot see the... Anything else because it\u2019s very dark. But the man on the picture seems to wear a hat and he seems to have a hoodie on as well. The picture is very mysterious, which I like about it, but for me I would like to understand more about the picture.\" > transcript.txt","title":"Command Line"},{"location":"cli_basics/#create-a-semantic-graph","text":"We can create a semantic graph from the transcript using either the command line interface (CLI) of python package. We can process a single transcript with the CLI like this CLI netts run transcript.txt outputs We can break this down into the following components: CLI Command transcript.txt outputs netts run Path to transcript path of output directory transcript.txt can be replaced with the full path to any .txt file. outputs can be replaced with the path to any directory. If the directory does not exist yet netts will create it. Netts uses Openie5 and CoreNLP under the hood. These are both Java programmes that we installed in the previous step. We use a context manager to start the servers, which makes sure they are both automatically shut down when processing finishes. Warning The servers are extremely memory hungry, using ~8GB. If the server fails to start you probably ran out of memory and failed silently. Try on a machine with more memory.","title":"Create a semantic graph"},{"location":"cli_basics/#outputs","text":"Once netts processes the transcript the output directory will contain two files: outputs/ transcript.pickle transcript.png The file prefix is taken from the input file (in this case transcript .txt ) transcript .pickle : A NetworkX MiltiDiGraph object. transcript .png : A plot of the graph.","title":"Outputs"},{"location":"cli_basics/#process-a-directory-of-transcripts","text":"If you have a folder of transcripts you can process the entire folder with the CLI. For example, if you have a folder called all_transcripts : all_transcripts/ transcript_1.txt transcript_2.txt ... you can process it with CLI netts run all_transcripts outputs","title":"Process a directory of transcripts"},{"location":"configuration/","text":"Advanced Configuration Netts can be configured using a TOML configuration file. This allows you to alter the ports used by netts's two servers, and alter defaults used to preprocess transcripts. The easiest way to configure netts is to create config file using the netts CLI which contains all the defaults: netts config > config.toml Validate your configuration When you make changes to your configuration file it is a good idea to check its still valid, has the correct syntax and has all the required fields. You can do this with: netts config-verify config.toml Netts expects config.toml to be in the current working directory. If it is somewhere else you can pass the path to the netts run command netts run transcript.txt OUTPUT_DIR --config PATH_TO_CONFIG","title":"Advanced"},{"location":"configuration/#advanced-configuration","text":"Netts can be configured using a TOML configuration file. This allows you to alter the ports used by netts's two servers, and alter defaults used to preprocess transcripts. The easiest way to configure netts is to create config file using the netts CLI which contains all the defaults: netts config > config.toml","title":"Advanced Configuration"},{"location":"configuration/#validate-your-configuration","text":"When you make changes to your configuration file it is a good idea to check its still valid, has the correct syntax and has all the required fields. You can do this with: netts config-verify config.toml Netts expects config.toml to be in the current working directory. If it is somewhere else you can pass the path to the netts run command netts run transcript.txt OUTPUT_DIR --config PATH_TO_CONFIG","title":"Validate your configuration"},{"location":"install/","text":"Getting Started Install netts Latest Stable Release To install the latest official release from PyPI: pip install netts Development Version If you would like the latest development version of netts install it from GitHub. This code may change at anytime. pip install git+https://github.com/alan-turing-institute/netts Warning Be aware that the development code is under active development and may change at any time. Install Additional Dependencies Netts requires the Java Runtime Environment. Instructions for downloading and installing for your operating system can be found here . Netts requires additional dependencies including CoreNLP and OpenIE . You can install them either directly from the netts CLI or in Python. CLI netts install Python import netts netts . install_dependencies () Info Dependencies are large (>5GB) and may take some time to download. Install to an Alternative Directory By default, the dependencies will be installed to a netts directory in your home directory. If you would like to install in a different location, set an environment variable called NETTS_DIR either on the commandline: export NETTS_DIR ={ DIRECTORY } or by creating a .env file in your working directory with these contents: NETTS_DIR ={ DIRECTORY } netts will create NETTS_DIR for you if it doesn't already exist. To verify which directory netts will use run: CLI netts home Python import netts settings = netts . get_settings () print ( settings . netts_dir )","title":"Getting Started"},{"location":"install/#getting-started","text":"","title":"Getting Started"},{"location":"install/#install-netts","text":"","title":"Install netts"},{"location":"install/#latest-stable-release","text":"To install the latest official release from PyPI: pip install netts","title":"Latest Stable Release"},{"location":"install/#development-version","text":"If you would like the latest development version of netts install it from GitHub. This code may change at anytime. pip install git+https://github.com/alan-turing-institute/netts Warning Be aware that the development code is under active development and may change at any time.","title":"Development Version"},{"location":"install/#install-additional-dependencies","text":"Netts requires the Java Runtime Environment. Instructions for downloading and installing for your operating system can be found here . Netts requires additional dependencies including CoreNLP and OpenIE . You can install them either directly from the netts CLI or in Python. CLI netts install Python import netts netts . install_dependencies () Info Dependencies are large (>5GB) and may take some time to download.","title":"Install Additional Dependencies"},{"location":"install/#install-to-an-alternative-directory","text":"By default, the dependencies will be installed to a netts directory in your home directory. If you would like to install in a different location, set an environment variable called NETTS_DIR either on the commandline: export NETTS_DIR ={ DIRECTORY } or by creating a .env file in your working directory with these contents: NETTS_DIR ={ DIRECTORY } netts will create NETTS_DIR for you if it doesn't already exist. To verify which directory netts will use run: CLI netts home Python import netts settings = netts . get_settings () print ( settings . netts_dir )","title":"Install to an Alternative Directory"},{"location":"pipeline/","text":"Pipeline Networks of Transcript Semantics (netts) is a network algorithm that builds on state-of-the-art Natural Language Processing libraries to create speech networks that capture semantic content. Netts takes transcripts of spoken text as input (e.g. I see a man ) and outputs a semantic speech network. Semantic Speech Network: Network that represents the semantic content of speech transcripts. In these networks, nodes are entities (e.g. I , man ). Edges are relations between nodes (e.g. see ). Netts can capture semantic links between nodes in speech content, even when semantically these nodes are separated by several sentences. The algorithm is robust against artefacts typical for spoken text. As described in CLI usage , netts can be used to process a single transcript or a folder of many transcripts. With about 40 seconds processing time per speech transcript, netts takes little time to process large batches of speech transcripts and therefore is ideal for the automated construction of speech networks from large datasets. In the following sections the netts processing pipeline is described in detail. See figure above for an overview of the netts pipeline. Preprocessing Netts first expands the most common English contractions (e.g. expanding I'm to I am ). It then removes interjections ( Mh , Uhm ). Netts also removes any transcription notes (e.g. timestamps, [inaudible] ) that were inserted by the transcriber. The user can pass a file of transcription notes that should be removed from the transcripts before processing. See Configuration for a step-by-step guide on passing custom transcription notes to netts for removal. Netts does not remove stop words or punctuation to stay as close to the original speech as possible. Netts then uses CoreNLP to perform sentence splitting, tokenization, part of speech tagging, lemmatization, dependency parsing and co-referencing on the transcript. Netts uses the default language model implemented in CoreNLP. We describe these Natural Language Processing steps briefly in the following. The transcript is first split into sentences (sentence splitting). It is then further split into meaningful entities, usually words (tokenization). Each word is assigned a part of speech label. The part of speech label indicates whether the word is a verb, noun, or another part of speech (part of speech tagging). Each word is also assigned their dictionary form or lemma (lemmatization). Next, the grammatical relationship between words is identified (dependency parsing). Finally, any occurrences where two or more expressions in the transcript refer to the same entity are identified (co-referencing). For example where a noun man and a pronoun he refer to the same person. Finding nodes and edges Netts submits each sentence to OpenIE5 for relation extraction. Openie5 extracts semantic relationships between entities from the sentence. For example, performing relation extraction on the sentence I see a man identifies the relation see between the entities I and a man . From these extracted relations, netts creates an initial list of the edges that will be present in the semantic speech network. In the edge list, the entities are the nodes and the relations are the edge labels. Next, netts uses the part of speech tags and dependency structure to extract edges defined by adjectives or prepositions: For instance, a man on the picture contains a preposition edge where the entity a man and the picture are linked by an edge labelled on . An example of an adjective edge would be dark background . Here, dark and background are linked by an implicit is . These adjective edges and preposition edges are added to the edge list. During the next processing steps this edge list is further refined. Refining nodes and edges After creating the edge list, netts uses the co-referencing information to merge nodes that refer to the same entity. This is to take into account cases different words refer to the same entity. For example in the case where the pronoun he is used to refer to a man or in the case where the synonym the guy is used to refer to a man . Every entity mentioned in the text should be represented by a unique node in the semantic speech network. Therefore, nodes referring to the same entity are merged by replacing the node label in the edge list with the most representative node label (first mention of the entity that is a noun). In the example above, he and the guy would be replaced by a man . Node labels are then cleaned of superfluous words such as determiners. For example, a man would turn into man . Constructing network In the final step, netts constructs a semantic speech network from the edge list using networkx . The network is then plotted and saves the output. The output consists of the networkx object, the network image and the log messages from netts. The resulting network (a MultiDiGraph ) is directed and unweighted, and can have parallel edges and self-loops. Parallel edges are two or more edges that link the same two nodes in the same direction. A self-loop is an edge that links a node with itself. See here for an example semantic speech network along with the corresponding speech transcript and stimulus picture.","title":"Pipeline"},{"location":"pipeline/#pipeline","text":"Networks of Transcript Semantics (netts) is a network algorithm that builds on state-of-the-art Natural Language Processing libraries to create speech networks that capture semantic content. Netts takes transcripts of spoken text as input (e.g. I see a man ) and outputs a semantic speech network. Semantic Speech Network: Network that represents the semantic content of speech transcripts. In these networks, nodes are entities (e.g. I , man ). Edges are relations between nodes (e.g. see ). Netts can capture semantic links between nodes in speech content, even when semantically these nodes are separated by several sentences. The algorithm is robust against artefacts typical for spoken text. As described in CLI usage , netts can be used to process a single transcript or a folder of many transcripts. With about 40 seconds processing time per speech transcript, netts takes little time to process large batches of speech transcripts and therefore is ideal for the automated construction of speech networks from large datasets. In the following sections the netts processing pipeline is described in detail. See figure above for an overview of the netts pipeline.","title":"Pipeline"},{"location":"pipeline/#preprocessing","text":"Netts first expands the most common English contractions (e.g. expanding I'm to I am ). It then removes interjections ( Mh , Uhm ). Netts also removes any transcription notes (e.g. timestamps, [inaudible] ) that were inserted by the transcriber. The user can pass a file of transcription notes that should be removed from the transcripts before processing. See Configuration for a step-by-step guide on passing custom transcription notes to netts for removal. Netts does not remove stop words or punctuation to stay as close to the original speech as possible. Netts then uses CoreNLP to perform sentence splitting, tokenization, part of speech tagging, lemmatization, dependency parsing and co-referencing on the transcript. Netts uses the default language model implemented in CoreNLP. We describe these Natural Language Processing steps briefly in the following. The transcript is first split into sentences (sentence splitting). It is then further split into meaningful entities, usually words (tokenization). Each word is assigned a part of speech label. The part of speech label indicates whether the word is a verb, noun, or another part of speech (part of speech tagging). Each word is also assigned their dictionary form or lemma (lemmatization). Next, the grammatical relationship between words is identified (dependency parsing). Finally, any occurrences where two or more expressions in the transcript refer to the same entity are identified (co-referencing). For example where a noun man and a pronoun he refer to the same person.","title":"Preprocessing"},{"location":"pipeline/#finding-nodes-and-edges","text":"Netts submits each sentence to OpenIE5 for relation extraction. Openie5 extracts semantic relationships between entities from the sentence. For example, performing relation extraction on the sentence I see a man identifies the relation see between the entities I and a man . From these extracted relations, netts creates an initial list of the edges that will be present in the semantic speech network. In the edge list, the entities are the nodes and the relations are the edge labels. Next, netts uses the part of speech tags and dependency structure to extract edges defined by adjectives or prepositions: For instance, a man on the picture contains a preposition edge where the entity a man and the picture are linked by an edge labelled on . An example of an adjective edge would be dark background . Here, dark and background are linked by an implicit is . These adjective edges and preposition edges are added to the edge list. During the next processing steps this edge list is further refined.","title":"Finding nodes and edges"},{"location":"pipeline/#refining-nodes-and-edges","text":"After creating the edge list, netts uses the co-referencing information to merge nodes that refer to the same entity. This is to take into account cases different words refer to the same entity. For example in the case where the pronoun he is used to refer to a man or in the case where the synonym the guy is used to refer to a man . Every entity mentioned in the text should be represented by a unique node in the semantic speech network. Therefore, nodes referring to the same entity are merged by replacing the node label in the edge list with the most representative node label (first mention of the entity that is a noun). In the example above, he and the guy would be replaced by a man . Node labels are then cleaned of superfluous words such as determiners. For example, a man would turn into man .","title":"Refining nodes and edges"},{"location":"pipeline/#constructing-network","text":"In the final step, netts constructs a semantic speech network from the edge list using networkx . The network is then plotted and saves the output. The output consists of the networkx object, the network image and the log messages from netts. The resulting network (a MultiDiGraph ) is directed and unweighted, and can have parallel edges and self-loops. Parallel edges are two or more edges that link the same two nodes in the same direction. A self-loop is an edge that links a node with itself. See here for an example semantic speech network along with the corresponding speech transcript and stimulus picture.","title":"Constructing network"},{"location":"post-processing/","text":"You can load the pickled graph objects back into Python for further analysis import pickle with open ( \"transcript.pkl\" , \"rb\" ) as graph_file : graph = pickle . load ( graph_file ) print ( type ( graph ))","title":"Analysing networks"},{"location":"python_basics/","text":"Netts package If you dont want to use the netts command line interface (CLI) or want more control over netts you can use the netts python package directly. Here we'll run through the CLI example in Python. Make sure you have a transcript in your working directory. Follow along - Example transcript To follow along create this example in a file by running the following command in a terminal echo \"I see a man and he is wearing a jacket. He is standing in the dark against a light post. On the picture there seems to be like a park and... Or trees but in those trees there are little balls of light reflections as well. I cannot see the... Anything else because it\u2019s very dark. But the man on the picture seems to wear a hat and he seems to have a hoodie on as well. The picture is very mysterious, which I like about it, but for me I would like to understand more about the picture.\" > transcript.txt Process a single transcript We can then process a single transcript using the following Python script, which we'll run through step by step. import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) First we load a Settings object which provides information about the netts configuration. We then check where netts will install addition dependencies, and finally download them. This can take a long time (~20min), so time to put the kettle on. Info If the dependencies have already been installed this function will do nothing. Start the CoreNLP and OpenIE5 servers import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) Netts uses Openie5 and CoreNLP under the hood. These are both Java programmes that we installed in the previous step. We use a context manager to start the servers, which makes sure they are both automatically shut down when processing finishes. Warning The servers are extremely memory hungry, using ~8GB. If the server fails to start you probably ran out of memory and failed silently. Try on a machine with more memory. Process a transcript import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) Next we load our transcript into memory, create a SpeechGraph object and then call its process method, passing our two servers and a configuration object. Here we use a default configuration object settings.netts_config.preprocess . Plot graph and save outputs import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) Finally we plot our graph, save it to file and also pickle our graph object for further analysis later. Refining the plot The network is plotted using spring-embedding , which tries to plot the network such that you get the least overlapping of nodes and edges with each other. This also means that each time you plot the network, it will look slightly different. If you are not happy with the way your network is plotted, try re-running the last few lines of code and look at the transcript.png image file again: fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) You can also open the figure in an interactive window by running: fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . show () When resizing the window, we see that the network automatically adjusts to the new window size and the nodes and edges spread out. This usually helps visualisation a lot. We therefore recommend trying out this step when processing your first few transcripts and inspecting the networks.","title":"Python"},{"location":"python_basics/#netts-package","text":"If you dont want to use the netts command line interface (CLI) or want more control over netts you can use the netts python package directly. Here we'll run through the CLI example in Python. Make sure you have a transcript in your working directory. Follow along - Example transcript To follow along create this example in a file by running the following command in a terminal echo \"I see a man and he is wearing a jacket. He is standing in the dark against a light post. On the picture there seems to be like a park and... Or trees but in those trees there are little balls of light reflections as well. I cannot see the... Anything else because it\u2019s very dark. But the man on the picture seems to wear a hat and he seems to have a hoodie on as well. The picture is very mysterious, which I like about it, but for me I would like to understand more about the picture.\" > transcript.txt","title":"Netts package"},{"location":"python_basics/#process-a-single-transcript","text":"We can then process a single transcript using the following Python script, which we'll run through step by step. import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) First we load a Settings object which provides information about the netts configuration. We then check where netts will install addition dependencies, and finally download them. This can take a long time (~20min), so time to put the kettle on. Info If the dependencies have already been installed this function will do nothing.","title":"Process a single transcript"},{"location":"python_basics/#start-the-corenlp-and-openie5-servers","text":"import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) Netts uses Openie5 and CoreNLP under the hood. These are both Java programmes that we installed in the previous step. We use a context manager to start the servers, which makes sure they are both automatically shut down when processing finishes. Warning The servers are extremely memory hungry, using ~8GB. If the server fails to start you probably ran out of memory and failed silently. Try on a machine with more memory.","title":"Start the CoreNLP and OpenIE5 servers"},{"location":"python_basics/#process-a-transcript","text":"import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) Next we load our transcript into memory, create a SpeechGraph object and then call its process method, passing our two servers and a configuration object. Here we use a default configuration object settings.netts_config.preprocess .","title":"Process a transcript"},{"location":"python_basics/#plot-graph-and-save-outputs","text":"import matplotlib.pyplot as plt import netts settings = netts . get_settings () print ( f \"Installing dependencies to { settings . netts_dir } \" ) netts . install_dependencies () with netts . OpenIEClient () as openie_client , netts . CoreNLPClient ( properties = { \"annotators\" : \"tokenize,ssplit,pos,lemma,parse,depparse,coref,openie\" }, ) as corenlp_client : with open ( \"transcript.txt\" , encoding = \"utf-8\" ) as f : transcript = f . read () graph = netts . SpeechGraph ( transcript ) graph . process ( openie_client = openie_client , corenlp_client = corenlp_client , preprocess_config = settings . netts_config . preprocess , ) fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) with open ( \"transcript.pkl\" , \"wb\" ) as output_f : netts . pickle_graph ( graph . graph , output_f ) Finally we plot our graph, save it to file and also pickle our graph object for further analysis later.","title":"Plot graph and save outputs"},{"location":"python_basics/#refining-the-plot","text":"The network is plotted using spring-embedding , which tries to plot the network such that you get the least overlapping of nodes and edges with each other. This also means that each time you plot the network, it will look slightly different. If you are not happy with the way your network is plotted, try re-running the last few lines of code and look at the transcript.png image file again: fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . savefig ( \"transcript.png\" ) You can also open the figure in an interactive window by running: fig , ax = plt . subplots () graph . plot_graph ( ax ) plt . show () When resizing the window, we see that the network automatically adjusts to the new window size and the nodes and edges spread out. This usually helps visualisation a lot. We therefore recommend trying out this step when processing your first few transcripts and inspecting the networks.","title":"Refining the plot"}]}